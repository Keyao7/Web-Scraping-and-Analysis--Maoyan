{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00000-49df5488-5924-40f1-af24-595ce185da67",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 13279,
    "execution_start": 1635307444438,
    "source_hash": "adb3cfb7",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4==0.0.1\n",
      "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
      "Collecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.10.0-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 4.7 MB/s \n",
      "\u001b[?25hCollecting soupsieve>1.2\n",
      "  Downloading soupsieve-2.2.1-py3-none-any.whl (33 kB)\n",
      "Building wheels for collected packages: bs4\n",
      "  Building wheel for bs4 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1271 sha256=92f25fbc7c2d7247ae1d708d175cf8c6ada618347417d32b2054312c89d05058\n",
      "  Stored in directory: /root/.cache/pip/wheels/0a/9e/ba/20e5bbc1afef3a491f0b3bb74d508f99403aabe76eda2167ca\n",
      "Successfully built bs4\n",
      "Installing collected packages: soupsieve, beautifulsoup4, bs4\n",
      "Successfully installed beautifulsoup4-4.10.0 bs4-0.0.1 soupsieve-2.2.1\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/root/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# install bs4\n",
    "!pip install bs4==0.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00000-b7d2cd5c-6957-4934-8c6f-edb78180a565",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 179,
    "execution_start": 1635307460337,
    "source_hash": "2bbb8a6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import successful\n"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "import codecs\n",
    "import csv\n",
    "print('import successful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00001-ff9c2be1-b1db-427a-b1ee-343da529fa3d",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5,
    "execution_start": 1634888675613,
    "source_hash": "b6bb0841",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define getting URL method\n",
    "def getAndParseURL(URL):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.81 Safari/537.36',\n",
    "        'Cookie': '__mta=146053643.1634884061994.1634885107048.1634885109200.5; uuid_n_v=v1; uuid=264C4800330111ECAC589362A74B013CA51B75C7C0664CDDA50026AE3AF024F4; _csrf=35ee60e223e05fc1134da2ac435c7c92744768354f76a32fc3f0c4e083708a90; Hm_lvt_703e94591e87be68cc8da0da7cbd0be2=1634884058; Hm_lpvt_703e94591e87be68cc8da0da7cbd0be2=1634885109; _lxsdk_cuid=17ca6aeff78c8-0e8b8997d181ab-4c3e2679-1fa400-17ca6aeff78c8; _lxsdk_s=17ca6aeff78-845-e63-6e1%7C%7C21; _lxsdk=264C4800330111ECAC589362A74B013CA51B75C7C0664CDDA50026AE3AF024F4; __mta=146018827.1634885103448.1634885103448.1634885108251.2',\n",
    "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9'\n",
    "    }\n",
    "    result = requests.get(url=URL, headers=headers)\n",
    "\n",
    "    soup = BeautifulSoup(result.text, 'html.parser')\n",
    "    return(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00002-d982002e-dcf3-4b90-a078-d68d4af9ddee",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 42455,
    "execution_start": 1634888677353,
    "source_hash": "97664e6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# scrap useful data from Ranking List\n",
    "Title = []\n",
    "moviesURLs = []\n",
    "Scores = []\n",
    "Name_of_actors = []\n",
    "Release_time = []\n",
    "for i in range(0, 100, 10):\n",
    "    time.sleep(3)\n",
    "    soup = getAndParseURL('https://maoyan.com/board/4?offset=' + str(i))\n",
    "\n",
    "    # get all sub link of ranking list\n",
    "    for x in soup.findAll('dd'):\n",
    "        moviesURLs.append(\"http://maoyan.com\" + x.a.get('href'))\n",
    "\n",
    "    # get score of each movie    \n",
    "    for y in soup.find_all('p', {\"class\": \"score\"}): # collecting rating information\n",
    "        score = ''\n",
    "        for i in y.children:\n",
    "            score += str(i.text)\n",
    "        Scores.append(score)\n",
    "\n",
    "    # get actor of each movie\n",
    "    for z in soup.findAll('p', {\"class\": \"star\"}):\n",
    "        Name_of_actors.append(z.text[20:][:-9])\n",
    "\n",
    "    # get release time of each movie\n",
    "    for j in soup.findAll('p', {\"class\": \"releasetime\"}):\n",
    "        Release_time.append(j.text[5:])\n",
    "    \n",
    "    #get title of each movie\n",
    "    for k in soup.findAll('p', {\"class\": \"name\"}):\n",
    "        Title.append(k.a.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00004-b531b7eb-8c1a-40ef-bf7b-01ab71435149",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 17,
    "execution_start": 1634710908669,
    "source_hash": "e87289a1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# store these data\n",
    "f=open(\"Actors.txt\",\"w\")\n",
    "for line in Name_of_actors:\n",
    "    f.write(line+'\\n')\n",
    "f.close()\n",
    "\n",
    "f=open(\"Release_time.txt\",\"w\")\n",
    "for line in Release_time:\n",
    "    f.write(line+'\\n')\n",
    "f.close()\n",
    "\n",
    "f=open(\"movie_list.txt\",\"w\")\n",
    "for line in moviesURLs:\n",
    "    f.write(line+'\\n')\n",
    "f.close()\n",
    "\n",
    "f=open(\"Scores.txt\",\"w\")\n",
    "for line in Scores:\n",
    "    f.write(line+'\\n')\n",
    "f.close()\n",
    "\n",
    "f=open(\"Title.txt\",\"w\")\n",
    "for line in Title:\n",
    "    f.write(line+'\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00007-0c14f500-662f-4f4c-8bb4-9930e9f61be5",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5,
    "execution_start": 1634885203201,
    "source_hash": "e52c4964",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "moviesURLs = []\n",
    "with open(\"movie_list.txt\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.strip('\\n')\n",
    "        moviesURLs.append(line)\n",
    "print(len(moviesURLs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00005-f81ba1fb-c7ce-45af-8b37-b555a61038b3",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 162,
    "execution_start": 1634888805407,
    "source_hash": "dfbc7916",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "# continue scrape from break point\n",
    "# load the index of break point\n",
    "tmp_index_of_movie = []\n",
    "with open(\"Director.txt\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.strip('\\n')\n",
    "        tmp_index_of_movie.append(line)\n",
    "index_of_movie = len(tmp_index_of_movie)\n",
    "print(index_of_movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00005-6b52bef8-1445-4e34-9a23-7a9858b70ba8",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 4,
    "execution_start": 1634888932807,
    "source_hash": "a7a1f2c0",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "# scrape data\n",
    "\n",
    "Name_of_director = []\n",
    "Cumulative_income = []\n",
    "Duration = []\n",
    "Type = []\n",
    "Film_making_area = []\n",
    "try:\n",
    "    for i in range(index_of_movie, 100):\n",
    "        url = moviesURLs[i]\n",
    "        soup = getAndParseURL(url)\n",
    "        time.sleep(1)\n",
    "        element = soup.find_all(\"a\", {\"class\": \"name\"})\n",
    "        try:\n",
    "            income = soup.find_all(\"div\", {\"class\": \"mbox-name\"})[-2].text\n",
    "        except:\n",
    "            income = ''\n",
    "        # member_group = []\n",
    "        # index = 0\n",
    "##############################################################################\n",
    "        # while True:\n",
    "        #     if element[index].text[7:][:-5] in member_group:\n",
    "        #         break\n",
    "        #     else:\n",
    "        #         member_group.append(element[index].text[7:][:-5])\n",
    "        #         index = index + 1\n",
    "\n",
    "        tmp = []\n",
    "        elem = soup.find_all('li', {\"class\": \"ellipsis\"})\n",
    "        for i in elem:\n",
    "            tmp.append(i.text)\n",
    "##############################################################################\n",
    "        # Director name\n",
    "        Name_of_director.append(element[0].text[7:][:-5])\n",
    "        time.sleep(1)\n",
    "        # Duration\n",
    "        Duration.append(tmp[1].split('/')[1][1:][:-9])\n",
    "        time.sleep(1)\n",
    "        # Moview type\n",
    "        Type.append(tmp[0][2:][:-2].split(' \\n '))\n",
    "        time.sleep(1)\n",
    "        #Film making area\n",
    "        Film_making_area.append(tmp[1][9:][:-9].split('\\n')[0])\n",
    "        time.sleep(1)\n",
    "        # Cumulative_income\n",
    "        Cumulative_income.append(income)\n",
    "##############################################################################\n",
    "except: # recored the break point\n",
    "    index_of_movie = i\n",
    "    print(index_of_movie)\n",
    "finally:\n",
    "    print(index_of_movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00006-056d69b1-a534-477f-8061-fa246f4cbb97",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 30,
    "execution_start": 1634888936021,
    "source_hash": "9c9e67f0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# break point \n",
    "# continue scrape from break point\n",
    "tmp_Director = []\n",
    "tmp_Area = []\n",
    "tmp_Duration = []\n",
    "tmp_Type = []\n",
    "tmp_income = []\n",
    "\n",
    "with open(\"Director.txt\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.strip('\\n')\n",
    "        tmp_Director.append(line)\n",
    "\n",
    "with open(\"Area.txt\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.strip('\\n')\n",
    "        tmp_Area.append(line)\n",
    "\n",
    "with open(\"Duration.txt\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.strip('\\n')\n",
    "        tmp_Duration.append(line)\n",
    "\n",
    "tmp_read_csv_Type = pd.read_csv('Type.csv')['Type']\n",
    "tmp_Type = list(tmp_read_csv_Type.values)\n",
    "\n",
    "with open(\"Cumulative_income.txt\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.strip('\\n')\n",
    "        tmp_income.append(line)\n",
    "\n",
    "for i in range(len(Duration)):\n",
    "    tmp_Duration.append(Duration[i])\n",
    "    tmp_Area.append(Film_making_area[i])\n",
    "    tmp_Director.append(Name_of_director[i])\n",
    "    tmp_Type.append(Type[i])\n",
    "    tmp_income.append(Cumulative_income[i])\n",
    "\n",
    "f=open(\"Duration.txt\",\"w\")\n",
    "for line in tmp_Duration:\n",
    "    f.write(line+'\\n')\n",
    "f.close()\n",
    "\n",
    "f=open(\"Director.txt\",\"w\")\n",
    "for line in tmp_Director:\n",
    "    f.write(line+'\\n')\n",
    "f.close()\n",
    "\n",
    "f=open(\"Area.txt\",\"w\")\n",
    "for line in tmp_Area:\n",
    "    f.write(line+'\\n')\n",
    "f.close()\n",
    "\n",
    "Type_pd = pd.DataFrame({'Type':tmp_Type})\n",
    "Type_pd.index = Type_pd.index+1\n",
    "Type_pd.to_csv('Type.csv', encoding='utf-8')\n",
    "\n",
    "f=open(\"Cumulative_income.txt\",\"w\")\n",
    "for line in tmp_income:\n",
    "    f.write(line+'\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00009-be388676-3dd7-41b8-a7d9-25da1f60929c",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 24,
    "execution_start": 1635307465247,
    "source_hash": "f6a0834d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# integration of data\n",
    "final_Director = []\n",
    "final_Area = []\n",
    "final_Duration = []\n",
    "final_Type = []\n",
    "final_Title = []\n",
    "final_Rating = []\n",
    "final_Actors = []\n",
    "final_Release_Time = []\n",
    "final_Movie_Information = []\n",
    "final_Cumulative_Income = []\n",
    "# name of director \n",
    "with open(\"Director.txt\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.strip('\\n')\n",
    "        final_Director.append(line)\n",
    "\n",
    "# film making area\n",
    "with open(\"Area.txt\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.strip('\\n')\n",
    "        final_Area.append(line)\n",
    "\n",
    "# duration of movie \n",
    "with open(\"Duration.txt\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.strip('\\n')\n",
    "        final_Duration.append(line)\n",
    "\n",
    "# cumulative income\n",
    "with open(\"Cumulative_income.txt\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.strip('\\n')\n",
    "        final_Cumulative_Income.append(line)\n",
    "\n",
    "# movie type \n",
    "tmp_read_csv_Type = pd.read_csv('Type.csv')['Type']\n",
    "final_Type = list(tmp_read_csv_Type.values)\n",
    "\n",
    "# movie title \n",
    "with open(\"Title.txt\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.strip('\\n')\n",
    "        final_Title.append(line)\n",
    "\n",
    "# movie rating \n",
    "with open(\"Scores.txt\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.strip('\\n')\n",
    "        final_Rating.append(line)\n",
    "\n",
    "# movie actors \n",
    "with open(\"Actors.txt\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.strip('\\n')\n",
    "        final_Actors.append(line)\n",
    "\n",
    "# release time \n",
    "with open(\"Release_time.txt\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.strip('\\n')\n",
    "        final_Release_Time.append(line)\n",
    "\n",
    "# movie informatiom\n",
    "with open(\"movie_list.txt\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.strip('\\n')\n",
    "        final_Movie_Information.append(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00010-64e53c96-34df-44b4-ab80-70ef26e4a52b",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 192,
    "execution_start": 1635307468869,
    "source_hash": "d60fda3d",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# record integration of data\n",
    "with open('Scraped_Data.csv','ab+') as csv_file:\n",
    "    csv_file.write(codecs.BOM_UTF8)\n",
    "csv_file = open('Scraped_Data.csv', 'a+', encoding='utf-8',newline='')\n",
    "writer = csv.writer(csv_file)\n",
    "writer.writerow(['Ranking','Title','Rating','Director', 'Actors','Duration', 'Relaese Time', 'Type', 'Making Area', 'Cumulative_income(ten thousand unit)', 'Movie Information'])\n",
    "\n",
    "for i in range(100):\n",
    "    with open('Scraped_Data.csv','ab+') as csv_file:\n",
    "        csv_file.write(codecs.BOM_UTF8)\n",
    "    csv_file = open('Scraped_Data.csv', 'a+', encoding='utf-8',newline='')\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow([str(i+1),final_Title[i], final_Rating[i], final_Director[i], final_Actors[i], \n",
    "                    final_Duration[i], final_Release_Time[i], final_Type[i], final_Area[i], \n",
    "                    final_Cumulative_Income[i], final_Movie_Information[i]])\n",
    "with open('Scraped_Data.csv','ab+') as csv_file:\n",
    "    csv_file.write(codecs.BOM_UTF8)\n",
    "csv_file = open('Scraped_Data.csv', 'a+', encoding='utf-8')\n",
    "writer = csv.writer(csv_file)                 \n",
    "writer.writerow([str(100),final_Title[99], final_Rating[99], final_Director[99], final_Actors[99], \n",
    "                    final_Duration[99], final_Release_Time[99], final_Type[99], final_Area[99], \n",
    "                    final_Cumulative_Income[99], final_Movie_Information[99]])"
   ]
  }
 ],
 "metadata": {
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "e0767af6-8ef7-46f3-85cb-544eecd6dd95",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
